# -*- coding: utf-8 -*-
# Streamlit UI for local RAG tool (ä¿®æ­£ç‰ˆ + export_texts patché©ç”¨)

import streamlit as st
import os
import json
import time
from rag_core import (
    build_index_from_folder,
    list_indexes,
    list_ollama_models,
    query_index,
    request_cancel,
    reset_cancel,
)

st.set_page_config(page_title="RAG Builder", layout="wide")
st.title("ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ« RAG ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆãƒ»æ¤œç´¢ãƒ„ãƒ¼ãƒ«")

file_phase = st.empty()
file_bar = st.progress(0)
chunk_phase = st.empty()
chunk_bar = st.progress(0)

def file_progress(idx, total, path):
    try:
        pct = idx / total if total else 0
    except Exception:
        pct = 0
    file_phase.write(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {idx}/{total} - {path}")
    try:
        file_bar.progress(pct)
    except Exception:
        file_bar.progress(0)

def chunk_progress(idx, total):
    try:
        pct = idx / total if total else 0
    except Exception:
        pct = 0
    chunk_phase.write(f"ğŸ§© ãƒãƒ¼ãƒ‰å‡¦ç†: {idx}/{total}")
    try:
        chunk_bar.progress(pct)
    except Exception:
        chunk_bar.progress(0)

st.markdown("All processing is **fully local**. Files never leave your machine.")

with st.sidebar:
    st.header("Settings")
    storage_dir = st.text_input("Storage directory", value=os.getenv("STORAGE_DIR", "storage"))

    embed_model_path = st.text_input(
        "Embedding model (local HuggingFace folder)",
        value=os.getenv("EMBED_MODEL_PATH", "local_models/all-MiniLM-L6-v2")
    )

    st.markdown("---")
    st.subheader("Ollama")
    models = []
    try:
        models = list_ollama_models()
    except Exception:
        models = []

    if models:
        llm_model = st.selectbox("Ollama ãƒ¢ãƒ‡ãƒ«é¸æŠ", models, index=0)
    else:
        llm_model = st.text_input("Ollama Model (manual)", value=os.getenv("OLLAMA_LLM_MODEL", "llama3.2:3b"))

    st.markdown("### Existing Indexes")
    idxs = list_indexes(storage_dir)
    st.write(idxs)

    if st.button("Refresh List"):
        idxs = list_indexes(storage_dir)
        st.write(idxs)

tabs = st.tabs(["ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ", "æ¤œç´¢"])

with tabs[0]:
    st.header("ğŸ“˜ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ")
    folder = st.text_input("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã®ãƒ‘ã‚¹")
    index_name = st.text_input("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å", value="myindex")

    embed_model = st.text_input("HuggingFace åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«", value=embed_model_path)
    chunk_size = st.number_input("chunk_size", 32, 4096, 512)
    chunk_overlap = st.number_input("chunk_overlap", 0, 2048, 100)

    # PATCH: export_texts checkbox è¿½åŠ 
    export_texts = st.checkbox("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ã—ã¦æ¤œæŸ»ã™ã‚‹ (extracted_texts ã« .txt ã‚’ä¿å­˜)", value=False)

    if st.button("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆé–‹å§‹", use_container_width=True):
        reset_cancel()
        file_phase.write("")
        chunk_phase.write("")
        file_bar.progress(0)
        chunk_bar.progress(0)

        if not folder:
            st.error("ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")
            res = build_index_from_folder(
                folder=folder,
                index_name=index_name,
                export_texts=export_texts,   # PATCH: å¼•æ•°è¿½åŠ 
                embed_model_path=embed_model,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                progress_callback=file_progress,
                chunk_callback=chunk_progress,
            )

            if res.get("status") == "ok":
                st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ï¼")

                # PATCH: export_texts ã®çµæœä¸€è¦§è¡¨ç¤º
                if export_texts:
                    extracted_dir = os.path.join(storage_dir, index_name, "extracted_texts")
#                    os.makedirs(extracted_dir, exist_ok=True)
                    if os.path.exists(extracted_dir):

                        files = sorted([f for f in os.listdir(extracted_dir) if f.endswith(".txt")])
                        if files:
                            st.markdown("### æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆä¸€è¦§ï¼ˆæœ€åˆã®æ•°ä»¶ï¼‰")
                            st.write(files[:50])
                            for fname in files[:3]:
                                try:
                                    with open(os.path.join(extracted_dir, fname), "r", encoding="utf-8") as fh:
                                        content = fh.read()
                                    with st.expander(f"Preview: {fname}"):
                                        st.text_area(f"{fname}", value=content[:20000], height=300)
                                except Exception:
                                    st.write(f"Failed to read {fname}")
                        else:
                            st.info("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã¯å‡ºåŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    else:
                        st.info("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

            elif res.get("status") == "cancelled":
                st.warning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {res.get('message')}")
                st.json(res)

    if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
        request_cancel()
        st.warning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«è¦æ±‚ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")

with tabs[1]:
    st.header("ğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢")
    indexes = list_indexes(storage_dir)
    index_sel = st.selectbox("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é¸æŠ", indexes)

    query = st.text_area("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›")
    llm_use = st.checkbox("LLM ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ (ã‚ªãƒ•ãªã‚‰å˜ç´”æ¤œç´¢)", value=False)

    if llm_use:
        st.write(f"é¸æŠãƒ¢ãƒ‡ãƒ«: {llm_model}")

    top_k = st.number_input("Retriever top_k", 1, 50, 5)

    if st.button("æ¤œç´¢å®Ÿè¡Œ", use_container_width=True):
        if not index_sel:
            st.error("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
        elif not query:
            st.error("ã‚¯ã‚¨ãƒªãŒç©ºã§ã™")
        else:
            st.info("æ¤œç´¢ä¸­...")
            res = query_index(
                index_name=index_sel,
                query=query,
                embed_model_path=embed_model,
                llm_model_name=llm_model,
                use_llm=llm_use,
                top_k=top_k,
            )

            if res.get("status") == "ok":
                st.success("æ¤œç´¢å®Œäº†")
                st.info(res.get("response"))
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {res.get('error')}")
